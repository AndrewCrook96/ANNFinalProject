{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349183da-67ec-4cbe-bef8-fa25b99399dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:17:58.371021: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-06 15:17:58.386925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-06 15:17:58.393021: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 15:17:58.404186: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, Flatten, Dense, Reshape, Conv1DTranspose, UpSampling1D\n",
    "from keras.models import Model\n",
    "\n",
    "def load_and_preprocess_data(hdf5_file, file_idx, spatial_idx, time_start_idx, time_end_idx):\n",
    "    \"\"\"\n",
    "    Load and preprocess data from the HDF5 file.\n",
    "    \n",
    "    Parameters:\n",
    "        hdf5_file (str): Path to the HDF5 file.\n",
    "        file_idx (int): Index of the file.\n",
    "        spatial_idx (int): Index of the spatial chunk to load.\n",
    "        time_start_idx (int): Start index for time chunks.\n",
    "        time_end_idx (int): End index for time chunks (inclusive).\n",
    "    Returns:\n",
    "        raw_data (np.array): Raw data (5000x100).\n",
    "        fft_data (np.array): FFT data (5000x100) (magnitude spectrum, normalized).\n",
    "    \"\"\"\n",
    "    with h5py.File(hdf5_file, 'r') as f:\n",
    "        raw_data = []\n",
    "        for t in range(time_start_idx, time_end_idx + 1):\n",
    "            chunk_name = f'chunk_{file_idx}_{t}_{spatial_idx}'\n",
    "            chunk = f[chunk_name][:]\n",
    "            raw_data.append(chunk)\n",
    "    \n",
    "    raw_data = np.concatenate(raw_data, axis=0)  # Combine time chunks\n",
    "    \n",
    "    # Perform FFT on the concatenated time chunk\n",
    "    fft_data = np.abs(np.fft.fft(raw_data, axis=0))  # FFT along time axis\n",
    "    \n",
    "    # Normalize raw and FFT data\n",
    "    raw_mean, raw_std = np.mean(raw_data), np.std(raw_data)\n",
    "    raw_data = (raw_data - raw_mean) / (raw_std + 1e-6)\n",
    "    \n",
    "    fft_mean, fft_std = np.mean(fft_data), np.std(fft_data)\n",
    "    fft_data = (fft_data - fft_mean) / (fft_std + 1e-6)\n",
    "    \n",
    "    return raw_data, fft_data\n",
    "\n",
    "def create_tf_dataset(hdf5_file, batch_size=32):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow dataset for efficient data loading.\n",
    "    \n",
    "    Parameters:\n",
    "        hdf5_file (str): Path to the HDF5 file.\n",
    "        batch_size (int): Batch size for training.\n",
    "    \n",
    "    Returns:\n",
    "        tf.data.Dataset: Preprocessed and batched dataset\n",
    "    \"\"\"\n",
    "    def generator():\n",
    "        with h5py.File(hdf5_file, 'r') as raw_f:\n",
    "            num_files = len(raw_f.keys()) // (87 * 30) - 1\n",
    "            for file_idx in range(num_files):\n",
    "                for spatial_idx in range(87):\n",
    "                    for time_idx in range(0, 27, 3):\n",
    "                        raw_data, fft_data = load_and_preprocess_data(\n",
    "                            hdf5_file, file_idx+1, spatial_idx, time_idx, time_idx + 4\n",
    "                        )\n",
    "                        yield raw_data, fft_data\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        generator, \n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(5000, 100), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(5000, 100), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def create_fft_autoencoder(input_dim=(5000, 100), model_name='fft_autoencoder'):\n",
    "    \"\"\"\n",
    "    Create an autoencoder neural network for FFT data.\n",
    "    \n",
    "    Parameters:\n",
    "        input_dim (tuple): Shape of the input data.\n",
    "        model_name (str): Name of the model.\n",
    "    \n",
    "    Returns:\n",
    "        model: Compiled autoencoder model.\n",
    "    \"\"\"\n",
    "    # Enable mixed precision training for potential speed improvement\n",
    "    keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "    \n",
    "    input_layer = Input(shape=input_dim)\n",
    "    \n",
    "    # Encoder\n",
    "    x = Conv1D(32, kernel_size=3, activation='relu', padding='same')(input_layer)\n",
    "    x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "    x = Conv1D(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling1D(pool_size=2, padding='same')(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    # Latent space\n",
    "    latent = Dense(128, activation='relu')(x)\n",
    "    \n",
    "    # Decoder\n",
    "    x = Dense(np.prod(input_dim), activation='relu')(latent)\n",
    "    x = Reshape((input_dim[0] // 4, input_dim[1] * 4))(x)\n",
    "    x = Conv1DTranspose(16, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    x = Conv1DTranspose(32, kernel_size=3, activation='relu', padding='same')(x)\n",
    "    x = UpSampling1D(size=2)(x)\n",
    "    output_layer = Conv1D(input_dim[1], kernel_size=3, activation='sigmoid', padding='same')(x)\n",
    "    \n",
    "    model = Model(input_layer, output_layer)\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='mse')\n",
    "    \n",
    "    # Optional: Plot model architecture\n",
    "    try:\n",
    "        keras.utils.plot_model(model, to_file=f\"{model_name}_architecture.png\", show_shapes=True)\n",
    "    except ImportError:\n",
    "        print(\"Could not plot model architecture. Ensure you have pydot and graphviz installed.\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "def train_fft_autoencoder(\n",
    "    hdf5_file, \n",
    "    model_name='fft_autoencoder.keras',\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    save_every=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Train FFT autoencoder with optimized data loading and training.\n",
    "    \n",
    "    Parameters:\n",
    "        hdf5_file (str): Path to the HDF5 file.\n",
    "        model_name (str): Name to save the model.\n",
    "        epochs (int): Number of training epochs.\n",
    "        batch_size (int): Batch size for training.\n",
    "        save_every (int): Save model every n epochs.\n",
    "    \"\"\"\n",
    "    # Check GPU availability\n",
    "    print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "    \n",
    "    # Create dataset\n",
    "    fft_dataset = create_tf_dataset(hdf5_file, batch_size)\n",
    "    \n",
    "    # Load existing model or create new one\n",
    "    if os.path.exists(model_name):\n",
    "        print(f\"Loading existing model: {model_name}\")\n",
    "        fft_autoencoder = keras.models.load_model(model_name)\n",
    "    else:\n",
    "        print(\"Creating new FFT autoencoder model\")\n",
    "        fft_autoencoder = create_fft_autoencoder()\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        patience=3, \n",
    "        monitor='loss', \n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    model_checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "        model_name, \n",
    "        save_best_only=True, \n",
    "        monitor='loss'\n",
    "    )\n",
    "    \n",
    "    # Tensorboard for monitoring (optional)\n",
    "    log_dir = os.path.join(\"logs\", \"fft_autoencoder_training\")\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    \n",
    "    # Training\n",
    "    history = fft_autoencoder.fit(\n",
    "        fft_dataset, \n",
    "        epochs=epochs, \n",
    "        callbacks=[\n",
    "            early_stopping, \n",
    "            model_checkpoint, \n",
    "            tensorboard_callback\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    print(f\"Training completed. Model saved as {model_name}\")\n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500eec51-2d50-4abc-ac82-e0fc3ddad485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_1200/1435684545.py:141: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "GPU Available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733523480.810676    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523480.832049    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523480.832129    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.022593    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.022741    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-06 15:18:01.022759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1733523481.022852    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-06 15:18:01.022884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 4057 MB memory:  -> device: 0, name: Quadro RTX 3000, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1733523481.030421    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.030631    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.030710    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.031071    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.031152    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.031217    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "I0000 00:00:1733523481.031637    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-06 15:18:01.031666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2112] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "I0000 00:00:1733523481.031761    1200 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-12-06 15:18:01.031789: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4057 MB memory:  -> device: 0, name: Quadro RTX 3000, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new FFT autoencoder model\n",
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733523484.496546    1260 service.cc:146] XLA service 0x7f030c00f120 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733523484.496597    1260 service.cc:154]   StreamExecutor device (0): Quadro RTX 3000, Compute Capability 7.5\n",
      "2024-12-06 15:18:04.553638: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-06 15:18:04.847971: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n",
      "I0000 00:00:1733523489.217418    1260 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   3524/Unknown \u001b[1m160s\u001b[0m 43ms/step - loss: 0.7710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:20:41.798350: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-12-06 15:20:41.798429: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-06 15:20:41.798447: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:20:41.798500: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n",
      "/home/acrook/anaconda3/lib/python3.12/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 45ms/step - loss: 0.7710\n",
      "Epoch 2/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.7280"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:23:08.455703: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-06 15:23:08.455748: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:23:08.455786: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 41ms/step - loss: 0.7280\n",
      "Epoch 3/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 41ms/step - loss: 0.7208\n",
      "Epoch 4/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:28:04.419555: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-06 15:28:04.419614: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:28:04.419699: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 43ms/step - loss: 0.7166\n",
      "Epoch 5/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - loss: 0.7145"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:30:33.981279: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:30:33.981393: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 42ms/step - loss: 0.7145\n",
      "Epoch 6/10\n",
      "\u001b[1m3523/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7135"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:33:10.525130: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:33:10.525208: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - loss: 0.7135\n",
      "Epoch 7/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 41ms/step - loss: 0.7116\n",
      "Epoch 8/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - loss: 0.7117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:38:11.897152: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-12-06 15:38:11.897233: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:38:11.897282: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - loss: 0.7117\n",
      "Epoch 9/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 0.7104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 15:41:04.416663: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 2196331488759118441\n",
      "2024-12-06 15:41:04.416795: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 10304361227340309533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 50ms/step - loss: 0.7104\n",
      "Epoch 10/10\n",
      "\u001b[1m3524/3524\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 44ms/step - loss: 0.7105\n",
      "Training completed. Model saved as autoencoder2.keras\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f04215bf8c0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "hdf5_file_path = 'raw_data.h5'\n",
    "    \n",
    "# Train FFT autoencoder\n",
    "train_fft_autoencoder(\n",
    "    hdf5_file=hdf5_file_path,\n",
    "    model_name='autoencoder2.keras',\n",
    "    epochs=10,\n",
    "    batch_size=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8018ee22-d53f-4ed1-9b32-a631485abfa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75374693-1da8-4eca-91d6-486daeaa247b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
